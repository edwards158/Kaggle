{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quroa Kaggle Challenge\n",
    "\n",
    "First Attempt at the Quora kaggle challenge.  Use just one word embedding and a simple CNN model,\n",
    "\n",
    "For each qid in the test set, you must predict whether the corresponding question_text is insincere (1) or not (0). Predictions should only be the integers 0 or 1.\n",
    "\n",
    "\n",
    "\n",
    "- https://www.kaggle.com/c/quora-insincere-questions-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richard\\Anaconda3\\envs\\tf15\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (56370, 2)\n"
     ]
    }
   ],
   "source": [
    "#read in the data\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets look at the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps are as follows:\n",
    " * Split the training dataset into train and val sample - cross val too expensive\n",
    " * Fill up the missing values in the text column with '_na_'\n",
    " * Tokenize the text column and convert them to vector sequences\n",
    " * Pad the sequence as needed - if the number of words in the text is greater than 'max_len' trunacate them to 'max_len' or if the number of words in the text is lesser than 'max_len' add zeros for remaining values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split to train and val\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)\n",
    "\n",
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].fillna(\"_na_\").values\n",
    "val_X = val_df[\"question_text\"].fillna(\"_na_\").values\n",
    "test_X = test_df[\"question_text\"].fillna(\"_na_\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What have been the best exhibits at the Museo del Prado in Madrid?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'char_level', 'document_count', 'filters', 'fit_on_sequences', 'fit_on_texts', 'index_docs', 'lower', 'num_words', 'oov_token', 'sequences_to_matrix', 'split', 'texts_to_matrix', 'texts_to_sequences', 'texts_to_sequences_generator', 'word_counts', 'word_docs', 'word_index']\n"
     ]
    }
   ],
   "source": [
    "print(dir(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 24, 113, 1, 34, 21469, 43, 1, 49489, 9003, 6, 5043], [9, 15, 8, 6912, 2938, 1211, 1694], [30, 3, 1, 34, 3180, 5062, 6, 9336, 848, 591], [9, 11, 8, 4220, 2110, 10, 9146, 6, 4249], [11, 14, 2192, 37, 488], [9, 11, 8, 33, 1394, 6742, 6, 2420, 1540, 6, 66, 1272, 6, 11482], [9, 11, 8, 76, 1, 5666, 985], [15, 14, 3573, 4, 7470, 31612, 20, 14, 24, 4, 53, 377, 13, 17], [11, 68, 16033, 536, 8556, 324, 7, 7856], [48, 14, 24, 50, 28901, 140, 57, 22, 28, 487]]\n"
     ]
    }
   ],
   "source": [
    "#produce a list of lists- each list is a integer representation of each word in the sentence\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "print((train_X[:10]))\n",
    "\n",
    "#the integer values represent the tokenizer index of each word in each sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat for the val and test\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences to the same length\n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1175509, 100)\n",
      "(130613, 100)\n",
      "(56370, 100)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(val_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Embeddings\n",
    "- glove.840B.300d - https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the entire GloVe word embedding file into memory as a dictionary of\n",
    "#word to embedding array\n",
    "path = 'D:\\\\ml_code\\\\embeddings\\\\glove.840B.300d\\\\'\n",
    "EMBEDDING_FILE = f'{path}glove.840B.300d.txt'\n",
    "\n",
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE,errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a matrix of one embedding for each word in the training\n",
    "#dataset. We can do that by enumerating all unique words in the Tokenizer.word index and\n",
    "#locating the embedding weight vector from the loaded GloVe embedding. The result is a matrix\n",
    "#of weights only for words we will see during training.\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "#initialise the embedding matrix\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "\n",
    "#for each word in vocab get weights\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 300)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 30001     \n",
      "=================================================================\n",
      "Total params: 15,030,001\n",
      "Trainable params: 15,030,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#prepare a first simple model\n",
    "# define model\n",
    "model = Sequential()\n",
    "input_length = Input(shape=(maxlen,))\n",
    "e = Embedding(max_features, embed_size, weights=[embedding_matrix], input_length=maxlen)\n",
    "model.add(e)\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/1\n",
      " - 88s - loss: 0.1401 - acc: 0.9494 - val_loss: 0.1250 - val_acc: 0.9528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cbc2558828>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run for just one epoch\n",
    "model.fit(train_X, train_y, batch_size=512, epochs=1, validation_data=(val_X, val_y),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 4us/step\n"
     ]
    }
   ],
   "source": [
    "#apply to validation set\n",
    "pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5002051983584132\n",
      "F1 score at threshold 0.11 is 0.5140422510207705\n",
      "F1 score at threshold 0.12 is 0.5271317829457365\n",
      "F1 score at threshold 0.13 is 0.5376727935591676\n",
      "F1 score at threshold 0.14 is 0.5472737932382254\n",
      "F1 score at threshold 0.15 is 0.5561982807102113\n",
      "F1 score at threshold 0.16 is 0.5636296265799333\n",
      "F1 score at threshold 0.17 is 0.5711400075748011\n",
      "F1 score at threshold 0.18 is 0.5775065537840044\n",
      "F1 score at threshold 0.19 is 0.5840607044168603\n",
      "F1 score at threshold 0.2 is 0.5896977284922196\n",
      "F1 score at threshold 0.21 is 0.5945084467920404\n",
      "F1 score at threshold 0.22 is 0.5987579942534063\n",
      "F1 score at threshold 0.23 is 0.6014584803575629\n",
      "F1 score at threshold 0.24 is 0.6054694970357621\n",
      "F1 score at threshold 0.25 is 0.6085395439107231\n",
      "F1 score at threshold 0.26 is 0.611706837186424\n",
      "F1 score at threshold 0.27 is 0.6144950652975775\n",
      "F1 score at threshold 0.28 is 0.6176782736139889\n",
      "F1 score at threshold 0.29 is 0.6179510797257189\n",
      "F1 score at threshold 0.3 is 0.6194103321415617\n",
      "F1 score at threshold 0.31 is 0.6201419931632921\n",
      "F1 score at threshold 0.32 is 0.6207666542612579\n",
      "F1 score at threshold 0.33 is 0.6209981675110489\n",
      "F1 score at threshold 0.34 is 0.6214196082710459\n",
      "F1 score at threshold 0.35 is 0.6213324509155085\n",
      "F1 score at threshold 0.36 is 0.6225763316246936\n",
      "F1 score at threshold 0.37 is 0.6226574371095729\n",
      "F1 score at threshold 0.38 is 0.6220983158852983\n",
      "F1 score at threshold 0.39 is 0.6208838572495834\n",
      "F1 score at threshold 0.4 is 0.6196593617392316\n",
      "F1 score at threshold 0.41 is 0.61933286351891\n",
      "F1 score at threshold 0.42 is 0.6173469387755103\n",
      "F1 score at threshold 0.43 is 0.6156796931191562\n",
      "F1 score at threshold 0.44 is 0.6144527227572838\n",
      "F1 score at threshold 0.45 is 0.6134931800110098\n",
      "F1 score at threshold 0.46 is 0.6117559891331192\n",
      "F1 score at threshold 0.47 is 0.6105604388753818\n",
      "F1 score at threshold 0.48 is 0.6094015480460638\n",
      "F1 score at threshold 0.49 is 0.606322753005534\n",
      "F1 score at threshold 0.5 is 0.6039286172807806\n"
     ]
    }
   ],
   "source": [
    "#look for a better threshold\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 0s 4us/step\n"
     ]
    }
   ],
   "source": [
    "pred_glove_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00277655],\n",
       "       [0.00458942],\n",
       "       [0.0101913 ],\n",
       "       ...,\n",
       "       [0.02646757],\n",
       "       [0.10272979],\n",
       "       [0.8694278 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_glove_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = (pred_glove_test_y>0.35).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to submit file\n",
    "#out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "#out_df['prediction'] = pred_test_y\n",
    "#out_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#do a clean up\n",
    "del word_index, embeddings_index, all_embs, embedding_matrix, model\n",
    "import gc; gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
