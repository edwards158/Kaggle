{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quroa Kaggle Challenge\n",
    "\n",
    "First Attempt at the Quora kaggle challenge.  Use just one word embedding and a simple CNN model,\n",
    "\n",
    "For each qid in the test set, you must predict whether the corresponding question_text is insincere (1) or not (0). Predictions should only be the integers 0 or 1.\n",
    "\n",
    "\n",
    "\n",
    "- https://www.kaggle.com/c/quora-insincere-questions-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "SEED = 2018\n",
    "import tensorflow as tf\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import gc,re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do a clean up\n",
    "#del word_index, embeddings_index, all_embs, embedding_matrix, model\n",
    "#import gc; gc.collect()\n",
    "#time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (56370, 2)\n"
     ]
    }
   ],
   "source": [
    "#read in the data\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets look at the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in \"/-'\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
    "        x = x.replace(punct, '')\n",
    "    return x\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "mispell_dict = {'colour':'color',\n",
    "                'centre':'center',\n",
    "                'didnt':'did not',\n",
    "                'doesnt':'does not',\n",
    "                'isnt':'is not',\n",
    "                'shouldnt':'should not',\n",
    "                'favourite':'favorite',\n",
    "                'travelling':'traveling',\n",
    "                'counselling':'counseling',\n",
    "                'theatre':'theater',\n",
    "                'cancelled':'canceled',\n",
    "                'labour':'labor',\n",
    "                'organisation':'organization',\n",
    "                'wwii':'world war 2',\n",
    "                'citicise':'criticize',\n",
    "                'instagram': 'social medium',\n",
    "                'whatsapp': 'social medium',\n",
    "                'snapchat': 'social medium'\n",
    "                }\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                      | 0/1175509 [00:00<?, ?it/s]\n",
      "\n",
      "  1%|▊                                                                     | 12978/1175509 [00:00<00:09, 121843.71it/s]\n",
      "\n",
      "  3%|█▊                                                                    | 30738/1175509 [00:00<00:08, 131025.48it/s]\n",
      "\n",
      "  4%|██▌                                                                   | 43211/1175509 [00:00<00:08, 128970.43it/s]\n",
      "\n",
      "  5%|███▎                                                                  | 56106/1175509 [00:00<00:08, 128490.52it/s]\n",
      "\n",
      "  6%|████▎                                                                 | 72248/1175509 [00:00<00:08, 136402.84it/s]\n",
      "\n",
      "  8%|█████▍                                                                | 90630/1175509 [00:00<00:07, 143017.62it/s]\n",
      "\n",
      "  9%|██████▎                                                              | 107104/1175509 [00:00<00:07, 148026.40it/s]\n",
      "\n",
      " 11%|███████▎                                                             | 125558/1175509 [00:00<00:06, 151929.48it/s]\n",
      "\n",
      " 12%|████████▎                                                            | 141988/1175509 [00:00<00:06, 154844.88it/s]\n",
      "\n",
      " 13%|█████████▎                                                           | 158221/1175509 [00:01<00:06, 156872.29it/s]\n",
      "\n",
      " 15%|██████████▎                                                          | 174676/1175509 [00:01<00:06, 158263.71it/s]\n",
      "\n",
      " 16%|███████████▏                                                         | 190932/1175509 [00:01<00:06, 159264.89it/s]\n",
      "\n",
      " 18%|████████████▎                                                        | 209246/1175509 [00:01<00:06, 159430.64it/s]\n",
      "\n",
      " 19%|█████████████▎                                                       | 225779/1175509 [00:01<00:05, 160564.96it/s]\n",
      "\n",
      " 21%|██████████████▏                                                      | 242115/1175509 [00:01<00:05, 161196.02it/s]\n",
      "\n",
      " 22%|███████████████▎                                                     | 260640/1175509 [00:01<00:05, 161637.62it/s]\n",
      "\n",
      " 24%|████████████████▏                                                    | 276778/1175509 [00:01<00:05, 160775.61it/s]\n",
      "\n",
      " 25%|█████████████████▏                                                   | 292839/1175509 [00:01<00:05, 160024.94it/s]\n",
      "\n",
      " 26%|██████████████████▏                                                  | 310564/1175509 [00:02<00:05, 158547.56it/s]\n",
      "\n",
      " 28%|███████████████████▏                                                 | 326444/1175509 [00:02<00:05, 158266.95it/s]\n",
      "\n",
      " 29%|████████████████████                                                 | 342390/1175509 [00:02<00:05, 158382.44it/s]\n",
      "\n",
      " 30%|█████████████████████                                                | 358346/1175509 [00:02<00:05, 158388.49it/s]\n",
      "\n",
      " 32%|██████████████████████▏                                              | 377160/1175509 [00:02<00:04, 159819.09it/s]\n",
      "\n",
      " 33%|███████████████████████                                              | 393144/1175509 [00:02<00:04, 159603.39it/s]\n",
      "\n",
      " 35%|████████████████████████                                             | 409106/1175509 [00:02<00:04, 159259.76it/s]\n",
      "\n",
      " 36%|█████████████████████████                                            | 427813/1175509 [00:02<00:04, 160169.64it/s]\n",
      "\n",
      " 38%|██████████████████████████                                           | 444246/1175509 [00:02<00:04, 160754.08it/s]\n",
      "\n",
      " 39%|███████████████████████████                                          | 460395/1175509 [00:02<00:04, 160640.11it/s]\n",
      "\n",
      " 41%|███████████████████████████▉                                         | 476461/1175509 [00:03<00:04, 158872.10it/s]\n",
      "\n",
      " 42%|████████████████████████████▉                                        | 492354/1175509 [00:03<00:04, 157601.50it/s]\n",
      "\n",
      " 43%|█████████████████████████████▉                                       | 510068/1175509 [00:03<00:04, 158798.57it/s]\n",
      "\n",
      " 45%|██████████████████████████████▉                                      | 526251/1175509 [00:03<00:04, 159562.93it/s]\n",
      "\n",
      " 46%|███████████████████████████████▊                                     | 542536/1175509 [00:03<00:03, 160398.01it/s]C:\\Users\\richard\\Anaconda3\\envs\\tf15\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n",
      "\n",
      "\n",
      " 48%|████████████████████████████████▊                                    | 558809/1175509 [00:03<00:03, 160919.01it/s]\n",
      "\n",
      " 49%|█████████████████████████████████▉                                   | 577426/1175509 [00:03<00:03, 161231.04it/s]\n",
      "\n",
      " 51%|██████████████████████████████████▊                                  | 593736/1175509 [00:03<00:03, 161132.87it/s]\n",
      "\n",
      " 52%|███████████████████████████████████▊                                 | 609962/1175509 [00:03<00:03, 161296.74it/s]\n",
      "\n",
      " 53%|████████████████████████████████████▊                                | 626298/1175509 [00:03<00:03, 161187.99it/s]\n",
      "\n",
      " 55%|█████████████████████████████████████▊                               | 644792/1175509 [00:04<00:03, 161457.93it/s]\n",
      "\n",
      " 56%|██████████████████████████████████████▊                              | 661168/1175509 [00:04<00:03, 161496.50it/s]\n",
      "\n",
      " 58%|███████████████████████████████████████▊                             | 677436/1175509 [00:04<00:03, 161644.92it/s]\n",
      "\n",
      " 59%|████████████████████████████████████████▊                            | 695927/1175509 [00:04<00:02, 161726.91it/s]\n",
      "\n",
      " 61%|█████████████████████████████████████████▊                           | 712604/1175509 [00:04<00:02, 161537.03it/s]\n",
      "\n",
      " 62%|██████████████████████████████████████████▊                          | 728870/1175509 [00:04<00:02, 160944.53it/s]\n",
      "\n",
      " 64%|███████████████████████████████████████████▊                         | 747400/1175509 [00:04<00:02, 160750.40it/s]\n",
      "\n",
      " 65%|████████████████████████████████████████████▊                        | 763476/1175509 [00:04<00:02, 159888.56it/s]\n",
      "\n",
      " 66%|█████████████████████████████████████████████▊                       | 779467/1175509 [00:04<00:02, 157662.31it/s]\n",
      "\n",
      " 68%|██████████████████████████████████████████████▋                      | 795242/1175509 [00:05<00:02, 156861.42it/s]\n",
      "\n",
      " 69%|███████████████████████████████████████████████▌                     | 811343/1175509 [00:05<00:02, 157703.22it/s]\n",
      "\n",
      " 70%|████████████████████████████████████████████████▌                    | 828336/1175509 [00:05<00:02, 158733.27it/s]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████▌                   | 844215/1175509 [00:05<00:02, 158087.44it/s]\n",
      "\n",
      " 73%|██████████████████████████████████████████████████▍                  | 860029/1175509 [00:05<00:02, 156343.30it/s]\n",
      "\n",
      " 74%|███████████████████████████████████████████████████▍                 | 875671/1175509 [00:05<00:01, 155084.16it/s]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████▍                | 893288/1175509 [00:05<00:01, 156757.03it/s]\n",
      "\n",
      " 77%|█████████████████████████████████████████████████████▍               | 909397/1175509 [00:05<00:01, 157915.61it/s]\n",
      "\n",
      " 79%|██████████████████████████████████████████████████████▎              | 925395/1175509 [00:05<00:01, 158314.70it/s]\n",
      "\n",
      " 80%|███████████████████████████████████████████████████████▎             | 941497/1175509 [00:05<00:01, 158659.88it/s]\n",
      "\n",
      " 81%|████████████████████████████████████████████████████████▏            | 957368/1175509 [00:06<00:01, 158210.99it/s]\n",
      "\n",
      " 83%|█████████████████████████████████████████████████████████            | 973193/1175509 [00:06<00:01, 156026.51it/s]\n",
      "\n",
      " 84%|██████████████████████████████████████████████████████████           | 988805/1175509 [00:06<00:01, 155698.82it/s]\n",
      "\n",
      " 86%|██████████████████████████████████████████████████████████▏         | 1006411/1175509 [00:06<00:01, 156943.85it/s]\n",
      "\n",
      " 87%|███████████████████████████████████████████████████████████▎        | 1024943/1175509 [00:06<00:00, 158204.43it/s]\n",
      "\n",
      " 89%|████████████████████████████████████████████████████████████▏       | 1040771/1175509 [00:06<00:00, 156589.88it/s]\n",
      "\n",
      " 90%|█████████████████████████████████████████████████████████████       | 1056439/1175509 [00:06<00:00, 155821.84it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████      | 1072029/1175509 [00:06<00:00, 155504.76it/s]\n",
      "\n",
      " 93%|██████████████████████████████████████████████████████████████▉     | 1087836/1175509 [00:06<00:00, 155925.57it/s]\n",
      "\n",
      " 94%|███████████████████████████████████████████████████████████████▉    | 1105443/1175509 [00:07<00:00, 156358.55it/s]\n",
      "\n",
      " 95%|████████████████████████████████████████████████████████████████▊   | 1121082/1175509 [00:07<00:00, 155501.27it/s]\n",
      "\n",
      " 97%|█████████████████████████████████████████████████████████████████▊  | 1136832/1175509 [00:07<00:00, 155756.07it/s]\n",
      "\n",
      " 98%|██████████████████████████████████████████████████████████████████▋ | 1152609/1175509 [00:07<00:00, 156031.04it/s]\n",
      "\n",
      " 99%|███████████████████████████████████████████████████████████████████▌| 1168390/1175509 [00:07<00:00, 156206.73it/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████| 1175509/1175509 [00:07<00:00, 157233.72it/s]\n",
      "\n",
      "  0%|                                                                                        | 0/56370 [00:00<?, ?it/s]\n",
      "\n",
      " 28%|████████████████████                                                    | 15748/56370 [00:00<00:00, 156289.62it/s]\n",
      "\n",
      " 56%|████████████████████████████████████████▏                               | 31426/56370 [00:00<00:00, 156391.25it/s]\n",
      "\n",
      " 88%|███████████████████████████████████████████████████████████████         | 49420/56370 [00:00<00:00, 157977.44it/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████| 56370/56370 [00:00<00:00, 157601.25it/s]\n",
      "\n",
      "  0%|                                                                                      | 0/1175509 [00:00<?, ?it/s]\n",
      "\n",
      "  1%|▌                                                                      | 10007/1175509 [00:00<00:11, 99994.76it/s]\n",
      "\n",
      "  2%|█▍                                                                    | 23354/1175509 [00:00<00:10, 107295.72it/s]\n",
      "\n",
      "  3%|██                                                                    | 35596/1175509 [00:00<00:10, 111182.99it/s]\n",
      "\n",
      "  4%|██▊                                                                   | 47957/1175509 [00:00<00:09, 114395.72it/s]\n",
      "\n",
      "  5%|███▌                                                                  | 60322/1175509 [00:00<00:09, 116791.60it/s]\n",
      "\n",
      "  6%|████▎                                                                 | 72565/1175509 [00:00<00:09, 118177.01it/s]\n",
      "\n",
      "  7%|█████                                                                 | 84953/1175509 [00:00<00:09, 119578.70it/s]\n",
      "\n",
      "  8%|█████▊                                                                | 97228/1175509 [00:00<00:08, 120253.71it/s]\n",
      "\n",
      "  9%|██████▍                                                              | 109605/1175509 [00:00<00:08, 121027.13it/s]\n",
      "\n",
      " 10%|███████▏                                                             | 122014/1175509 [00:01<00:08, 121656.68it/s]\n",
      "\n",
      " 11%|███████▉                                                             | 134325/1175509 [00:01<00:08, 121825.19it/s]\n",
      "\n",
      " 12%|████████▌                                                            | 146678/1175509 [00:01<00:08, 122066.53it/s]\n",
      "\n",
      " 14%|█████████▎                                                           | 159320/1175509 [00:01<00:08, 123057.84it/s]\n",
      "\n",
      " 15%|██████████▏                                                          | 173202/1175509 [00:01<00:08, 124999.76it/s]\n",
      "\n",
      " 16%|██████████▉                                                          | 187035/1175509 [00:01<00:07, 123847.05it/s]\n",
      "\n",
      " 17%|███████████▋                                                         | 199716/1175509 [00:01<00:07, 124449.93it/s]\n",
      "\n",
      " 18%|████████████▍                                                        | 212435/1175509 [00:01<00:07, 124990.19it/s]\n",
      "\n",
      " 19%|█████████████▏                                                       | 225252/1175509 [00:01<00:07, 125667.93it/s]\n",
      "\n",
      " 20%|█████████████▉                                                       | 238134/1175509 [00:01<00:07, 126313.24it/s]\n",
      "\n",
      " 21%|██████████████▋                                                      | 251042/1175509 [00:02<00:07, 126855.61it/s]\n",
      "\n",
      " 22%|███████████████▍                                                     | 263776/1175509 [00:02<00:07, 126723.42it/s]\n",
      "\n",
      " 24%|████████████████▏                                                    | 276536/1175509 [00:02<00:07, 126720.33it/s]\n",
      "\n",
      " 25%|████████████████▉                                                    | 289207/1175509 [00:02<00:07, 125689.65it/s]\n",
      "\n",
      " 26%|█████████████████▋                                                   | 301777/1175509 [00:02<00:06, 125033.10it/s]\n",
      "\n",
      " 27%|██████████████████▌                                                  | 316181/1175509 [00:02<00:06, 126894.81it/s]\n",
      "\n",
      " 28%|███████████████████▎                                                 | 329378/1175509 [00:02<00:06, 128215.18it/s]\n",
      "\n",
      " 29%|████████████████████▏                                                | 344502/1175509 [00:02<00:06, 129244.68it/s]\n",
      "\n",
      " 30%|█████████████████████                                                | 357791/1175509 [00:02<00:06, 129826.59it/s]\n",
      "\n",
      " 32%|█████████████████████▊                                               | 371265/1175509 [00:02<00:06, 130269.93it/s]\n",
      "\n",
      " 33%|██████████████████████▋                                              | 386254/1175509 [00:03<00:06, 130963.81it/s]\n",
      "\n",
      " 34%|███████████████████████▍                                             | 399469/1175509 [00:03<00:05, 130746.24it/s]\n",
      "\n",
      " 35%|████████████████████████▏                                            | 412805/1175509 [00:03<00:05, 130573.03it/s]\n",
      "\n",
      " 36%|█████████████████████████                                            | 427897/1175509 [00:03<00:05, 130680.87it/s]\n",
      "\n",
      " 38%|█████████████████████████▉                                           | 441245/1175509 [00:03<00:05, 130885.02it/s]\n",
      "\n",
      " 39%|██████████████████████████▊                                          | 456115/1175509 [00:03<00:05, 131095.54it/s]\n",
      "\n",
      " 40%|███████████████████████████▌                                         | 469398/1175509 [00:03<00:05, 131102.55it/s]\n",
      "\n",
      " 41%|████████████████████████████▎                                        | 482598/1175509 [00:03<00:05, 131227.15it/s]\n",
      "\n",
      " 42%|█████████████████████████████▏                                       | 497247/1175509 [00:03<00:05, 130980.31it/s]\n",
      "\n",
      " 43%|██████████████████████████████                                       | 511227/1175509 [00:04<00:05, 131042.76it/s]\n",
      "\n",
      " 45%|██████████████████████████████▉                                      | 526115/1175509 [00:04<00:04, 131223.38it/s]\n",
      "\n",
      " 46%|███████████████████████████████▋                                     | 539238/1175509 [00:04<00:04, 130793.03it/s]\n",
      "\n",
      " 47%|████████████████████████████████▍                                    | 552318/1175509 [00:04<00:04, 128980.95it/s]\n",
      "\n",
      " 48%|█████████████████████████████████▎                                   | 567010/1175509 [00:04<00:04, 128575.58it/s]\n",
      "\n",
      " 50%|██████████████████████████████████▏                                  | 582147/1175509 [00:04<00:04, 129413.86it/s]\n",
      "\n",
      " 51%|███████████████████████████████████                                  | 597140/1175509 [00:04<00:04, 129707.21it/s]\n",
      "\n",
      " 52%|███████████████████████████████████▊                                 | 610454/1175509 [00:04<00:04, 129740.74it/s]\n",
      "\n",
      " 53%|████████████████████████████████████▋                                | 625361/1175509 [00:04<00:04, 130018.42it/s]\n",
      "\n",
      " 54%|█████████████████████████████████████▍                               | 638681/1175509 [00:05<00:04, 129910.48it/s]\n",
      "\n",
      " 55%|██████████████████████████████████████▎                              | 651799/1175509 [00:05<00:04, 130046.09it/s]\n",
      "\n",
      " 57%|███████████████████████████████████████▏                             | 666830/1175509 [00:05<00:03, 130153.25it/s]\n",
      "\n",
      " 58%|███████████████████████████████████████▉                             | 680064/1175509 [00:05<00:03, 130575.80it/s]\n",
      "\n",
      " 59%|████████████████████████████████████████▋                            | 693269/1175509 [00:05<00:03, 130781.96it/s]\n",
      "\n",
      " 60%|█████████████████████████████████████████▌                           | 708251/1175509 [00:05<00:03, 130986.68it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████████████████████████████▎                          | 721379/1175509 [00:05<00:03, 130646.99it/s]\n",
      "\n",
      " 62%|███████████████████████████████████████████                          | 734445/1175509 [00:05<00:03, 128522.70it/s]\n",
      "\n",
      " 64%|███████████████████████████████████████████▊                         | 747306/1175509 [00:05<00:03, 127142.57it/s]\n",
      "\n",
      " 65%|████████████████████████████████████████████▋                        | 761405/1175509 [00:05<00:03, 127232.32it/s]\n",
      "\n",
      " 66%|█████████████████████████████████████████████▌                       | 776319/1175509 [00:06<00:03, 128462.88it/s]\n",
      "\n",
      " 67%|██████████████████████████████████████████████▎                      | 789485/1175509 [00:06<00:02, 129257.15it/s]\n",
      "\n",
      " 68%|███████████████████████████████████████████████                      | 802810/1175509 [00:06<00:02, 129859.91it/s]\n",
      "\n",
      " 70%|████████████████████████████████████████████████                     | 817959/1175509 [00:06<00:02, 130361.44it/s]\n",
      "\n",
      " 71%|████████████████████████████████████████████████▊                    | 831252/1175509 [00:06<00:02, 130286.92it/s]\n",
      "\n",
      " 72%|█████████████████████████████████████████████████▌                   | 844310/1175509 [00:06<00:02, 130181.10it/s]\n",
      "\n",
      " 73%|██████████████████████████████████████████████████▍                  | 859194/1175509 [00:06<00:02, 130363.49it/s]\n",
      "\n",
      " 74%|███████████████████████████████████████████████████▏                 | 872475/1175509 [00:06<00:02, 130555.59it/s]\n",
      "\n",
      " 75%|████████████████████████████████████████████████████                 | 887172/1175509 [00:06<00:02, 129765.17it/s]\n",
      "\n",
      " 77%|████████████████████████████████████████████████████▊                | 900407/1175509 [00:07<00:02, 130017.39it/s]\n",
      "\n",
      " 78%|█████████████████████████████████████████████████████▌               | 913573/1175509 [00:07<00:02, 130368.72it/s]\n",
      "\n",
      " 79%|██████████████████████████████████████████████████████▍              | 926782/1175509 [00:07<00:01, 130759.94it/s]\n",
      "\n",
      " 80%|███████████████████████████████████████████████████████▎             | 941901/1175509 [00:07<00:01, 130863.04it/s]\n",
      "\n",
      " 81%|████████████████████████████████████████████████████████             | 955396/1175509 [00:07<00:01, 130670.77it/s]\n",
      "\n",
      " 82%|████████████████████████████████████████████████████████▊            | 968464/1175509 [00:07<00:01, 130655.64it/s]\n",
      "\n",
      " 84%|█████████████████████████████████████████████████████████▋           | 983232/1175509 [00:07<00:01, 130556.33it/s]\n",
      "\n",
      " 85%|██████████████████████████████████████████████████████████▍          | 996625/1175509 [00:07<00:01, 131030.65it/s]\n",
      "\n",
      " 86%|██████████████████████████████████████████████████████████▍         | 1009745/1175509 [00:07<00:01, 130869.71it/s]\n",
      "\n",
      " 87%|███████████████████████████████████████████████████████████▏        | 1022892/1175509 [00:07<00:01, 130475.86it/s]\n",
      "\n",
      " 88%|████████████████████████████████████████████████████████████        | 1037972/1175509 [00:08<00:01, 130659.55it/s]\n",
      "\n",
      " 89%|████████████████████████████████████████████████████████████▊       | 1051039/1175509 [00:08<00:00, 130508.24it/s]\n",
      "\n",
      " 91%|█████████████████████████████████████████████████████████████▌      | 1064101/1175509 [00:08<00:00, 129940.54it/s]\n",
      "\n",
      " 92%|██████████████████████████████████████████████████████████████▍     | 1079104/1175509 [00:08<00:00, 130342.04it/s]\n",
      "\n",
      " 93%|███████████████████████████████████████████████████████████████▏    | 1092488/1175509 [00:08<00:00, 130382.87it/s]\n",
      "\n",
      " 94%|████████████████████████████████████████████████████████████████    | 1107594/1175509 [00:08<00:00, 130688.56it/s]\n",
      "\n",
      " 95%|████████████████████████████████████████████████████████████████▊   | 1120866/1175509 [00:08<00:00, 130661.51it/s]\n",
      "\n",
      " 97%|█████████████████████████████████████████████████████████████████▋  | 1135849/1175509 [00:08<00:00, 130904.12it/s]\n",
      "\n",
      " 98%|██████████████████████████████████████████████████████████████████▍ | 1149145/1175509 [00:08<00:00, 130489.39it/s]\n",
      "\n",
      " 99%|███████████████████████████████████████████████████████████████████▎| 1164023/1175509 [00:09<00:00, 130514.74it/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████| 1175509/1175509 [00:09<00:00, 128374.27it/s]\n",
      "\n",
      "  0%|                                                                                        | 0/56370 [00:00<?, ?it/s]\n",
      "\n",
      " 26%|██████████████████▌                                                     | 14557/56370 [00:00<00:00, 126977.74it/s]\n",
      "\n",
      " 52%|█████████████████████████████████████▋                                  | 29523/56370 [00:00<00:00, 128000.75it/s]\n",
      "\n",
      " 76%|██████████████████████████████████████████████████████▌                 | 42727/56370 [00:00<00:00, 128672.04it/s]\n",
      "\n",
      " 99%|███████████████████████████████████████████████████████████████████████▌| 55993/56370 [00:00<00:00, 129279.85it/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████| 56370/56370 [00:00<00:00, 128774.20it/s]\n",
      "\n",
      "  0%|                                                                                      | 0/1175509 [00:00<?, ?it/s]\n",
      "\n",
      "  2%|█▎                                                                    | 22077/1175509 [00:00<00:05, 219013.63it/s]\n",
      "\n",
      "  4%|██▉                                                                   | 49293/1175509 [00:00<00:04, 232137.99it/s]\n",
      "\n",
      "  7%|████▌                                                                 | 76658/1175509 [00:00<00:04, 242629.95it/s]\n",
      "\n",
      "  9%|██████▏                                                              | 104589/1175509 [00:00<00:04, 252008.36it/s]\n",
      "\n",
      " 11%|███████▊                                                             | 133038/1175509 [00:00<00:04, 260423.68it/s]\n",
      "\n",
      " 14%|█████████▌                                                           | 162120/1175509 [00:00<00:03, 268166.76it/s]\n",
      "\n",
      " 16%|███████████▏                                                         | 190778/1175509 [00:00<00:03, 273383.56it/s]\n",
      "\n",
      " 19%|████████████▉                                                        | 219412/1175509 [00:00<00:03, 276456.19it/s]\n",
      "\n",
      " 21%|██████████████▌                                                      | 248090/1175509 [00:00<00:03, 278666.86it/s]\n",
      "\n",
      " 24%|████████████████▏                                                    | 276551/1175509 [00:01<00:03, 279845.42it/s]\n",
      "\n",
      " 26%|█████████████████▉                                                   | 305050/1175509 [00:01<00:03, 280761.78it/s]\n",
      "\n",
      " 29%|███████████████████▊                                                 | 337533/1175509 [00:01<00:02, 281795.90it/s]\n",
      "\n",
      " 32%|█████████████████████▊                                               | 371342/1175509 [00:01<00:02, 285931.04it/s]\n",
      "\n",
      " 34%|███████████████████████▌                                             | 401281/1175509 [00:01<00:02, 289459.19it/s]\n",
      "\n",
      " 37%|█████████████████████████▏                                           | 430119/1175509 [00:01<00:02, 286942.56it/s]\n",
      "\n",
      " 39%|██████████████████████████▉                                          | 459032/1175509 [00:01<00:02, 286876.54it/s]\n",
      "\n",
      " 41%|████████████████████████████▋                                        | 487670/1175509 [00:01<00:02, 286098.70it/s]\n",
      "\n",
      " 44%|██████████████████████████████▌                                      | 521184/1175509 [00:01<00:02, 288450.79it/s]\n",
      "\n",
      " 47%|████████████████████████████████▎                                    | 550156/1175509 [00:01<00:02, 288366.58it/s]\n",
      "\n",
      " 50%|██████████████████████████████████▎                                  | 584232/1175509 [00:02<00:02, 291301.93it/s]\n",
      "\n",
      " 52%|████████████████████████████████████                                 | 614426/1175509 [00:02<00:01, 293221.03it/s]\n",
      "\n",
      " 55%|█████████████████████████████████████▊                               | 643886/1175509 [00:02<00:01, 292787.25it/s]\n",
      "\n",
      " 57%|███████████████████████████████████████▌                             | 673166/1175509 [00:02<00:01, 291276.18it/s]\n",
      "\n",
      " 60%|█████████████████████████████████████████▏                           | 702410/1175509 [00:02<00:01, 291373.80it/s]\n",
      "\n",
      " 63%|███████████████████████████████████████████▏                         | 736217/1175509 [00:02<00:01, 292726.89it/s]\n",
      "\n",
      " 65%|████████████████████████████████████████████▉                        | 766331/1175509 [00:02<00:01, 293833.76it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████▋                      | 796313/1175509 [00:02<00:01, 295071.98it/s]\n",
      "\n",
      " 70%|████████████████████████████████████████████████▍                    | 825824/1175509 [00:02<00:01, 293004.48it/s]\n",
      "\n",
      " 73%|██████████████████████████████████████████████████▏                  | 855131/1175509 [00:02<00:01, 291512.78it/s]\n",
      "\n",
      " 76%|████████████████████████████████████████████████████▏                | 888444/1175509 [00:03<00:00, 291574.93it/s]\n",
      "\n",
      " 78%|██████████████████████████████████████████████████████               | 921791/1175509 [00:03<00:00, 293382.10it/s]\n",
      "\n",
      " 81%|███████████████████████████████████████████████████████▊             | 951739/1175509 [00:03<00:00, 294191.64it/s]\n",
      "\n",
      " 84%|█████████████████████████████████████████████████████████▋           | 982156/1175509 [00:03<00:00, 294977.00it/s]\n",
      "\n",
      " 86%|██████████████████████████████████████████████████████████▊         | 1015890/1175509 [00:03<00:00, 295303.11it/s]\n",
      "\n",
      " 89%|████████████████████████████████████████████████████████████▍       | 1045776/1175509 [00:03<00:00, 296011.56it/s]\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████████▏     | 1075564/1175509 [00:03<00:00, 296297.74it/s]\n",
      "\n",
      " 94%|███████████████████████████████████████████████████████████████▉    | 1105817/1175509 [00:03<00:00, 296702.33it/s]\n",
      "\n",
      " 97%|█████████████████████████████████████████████████████████████████▉  | 1139911/1175509 [00:03<00:00, 297496.29it/s]\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████▋| 1170289/1175509 [00:04<00:00, 298105.93it/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████| 1175509/1175509 [00:04<00:00, 287273.47it/s]\n",
      "\n",
      "  0%|                                                                                        | 0/56370 [00:00<?, ?it/s]\n",
      "\n",
      " 58%|█████████████████████████████████████████▍                              | 32476/56370 [00:00<00:00, 281889.20it/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████| 56370/56370 [00:00<00:00, 284328.99it/s]"
     ]
    }
   ],
   "source": [
    "# Clean the text\n",
    "train_df[\"question_text\"] = train_df[\"question_text\"].progress_apply(lambda x: clean_text(x))\n",
    "test_df[\"question_text\"] = test_df[\"question_text\"].progress_apply(lambda x: clean_text(x))\n",
    "\n",
    "# Clean numbers\n",
    "train_df[\"question_text\"] = train_df[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\n",
    "test_df[\"question_text\"] = test_df[\"question_text\"].progress_apply(lambda x: clean_numbers(x))\n",
    "\n",
    "# Clean speelings\n",
    "train_df[\"question_text\"] = train_df[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))\n",
    "test_df[\"question_text\"] = test_df[\"question_text\"].progress_apply(lambda x: replace_typical_misspell(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>651064</th>\n",
       "      <td>7f8590ef60e30b4344fd</td>\n",
       "      <td>What have been the best exhibits at the Museo ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294259</th>\n",
       "      <td>fda9538a2e0a5b2dfc3c</td>\n",
       "      <td>How can I rotate batch image files</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205706</th>\n",
       "      <td>ec528b4e3abc3347cd21</td>\n",
       "      <td>Which is the best cable operator in Thane west...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460090</th>\n",
       "      <td>5a1a41ea2086f2264eab</td>\n",
       "      <td>How do I expand factor and simplify in algebra</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277213</th>\n",
       "      <td>fa4f394af94b2b094e15</td>\n",
       "      <td>Do you judge people often</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "651064   7f8590ef60e30b4344fd   \n",
       "1294259  fda9538a2e0a5b2dfc3c   \n",
       "1205706  ec528b4e3abc3347cd21   \n",
       "460090   5a1a41ea2086f2264eab   \n",
       "1277213  fa4f394af94b2b094e15   \n",
       "\n",
       "                                             question_text  target  \n",
       "651064   What have been the best exhibits at the Museo ...       0  \n",
       "1294259                 How can I rotate batch image files       0  \n",
       "1205706  Which is the best cable operator in Thane west...       0  \n",
       "460090      How do I expand factor and simplify in algebra       0  \n",
       "1277213                          Do you judge people often       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richard\\Anaconda3\\envs\\tf15\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps are as follows:\n",
    " * Split the training dataset into train and val sample - cross val too expensive\n",
    " * Fill up the missing values in the text column with '_na_'\n",
    " * Tokenize the text column and convert them to vector sequences\n",
    " * Pad the sequence as needed - if the number of words in the text is greater than 'max_len' trunacate them to 'max_len' or if the number of words in the text is lesser than 'max_len' add zeros for remaining values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split to train and val\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)\n",
    "\n",
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].fillna(\"_na_\").values\n",
    "val_X = val_df[\"question_text\"].fillna(\"_na_\").values\n",
    "test_X = test_df[\"question_text\"].fillna(\"_na_\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richard\\Anaconda3\\envs\\tf15\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "#produce a list of lists- each list is a integer representation of each word in the sentence\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "#print((train_X[:10]))\n",
    "\n",
    "\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richard\\Anaconda3\\envs\\tf15\\lib\\site-packages\\tqdm\\_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = 'D:\\\\ml_code\\\\embeddings\\\\glove.840B.300d\\\\glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE,errors='ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "print(nb_words)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 952162 samples, validate on 105796 samples\n",
      "Epoch 1/3\n",
      " - 122s - loss: 0.1129 - acc: 0.9562 - val_loss: 0.1038 - val_acc: 0.9595\n",
      "Epoch 2/3\n",
      " - 120s - loss: 0.0931 - acc: 0.9631 - val_loss: 0.1027 - val_acc: 0.9592\n",
      "Epoch 3/3\n",
      " - 119s - loss: 0.0788 - acc: 0.9687 - val_loss: 0.1071 - val_acc: 0.9589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a70caa7be0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run for just one epoch\n",
    "model.fit(train_X, train_y, batch_size=512, epochs=3, validation_data=(val_X, val_y),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105796/105796 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 3s 33us/step\n"
     ]
    }
   ],
   "source": [
    "#apply to validation set\n",
    "pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.6020408163265306\n",
      "F1 score at threshold 0.11 is 0.6091571949388805\n",
      "F1 score at threshold 0.12 is 0.6152756591850076\n",
      "F1 score at threshold 0.13 is 0.6209873810050919\n",
      "F1 score at threshold 0.14 is 0.6259627818069377\n",
      "F1 score at threshold 0.15 is 0.6313211845102505\n",
      "F1 score at threshold 0.16 is 0.6348803689824157\n",
      "F1 score at threshold 0.17 is 0.6397802326261033\n",
      "F1 score at threshold 0.18 is 0.6427811280595956\n",
      "F1 score at threshold 0.19 is 0.6461759253722419\n",
      "F1 score at threshold 0.2 is 0.648821752265861\n",
      "F1 score at threshold 0.21 is 0.650634765625\n",
      "F1 score at threshold 0.22 is 0.6528874629812439\n",
      "F1 score at threshold 0.23 is 0.6544434050514499\n",
      "F1 score at threshold 0.24 is 0.6552613371910182\n",
      "F1 score at threshold 0.25 is 0.6566842205443817\n",
      "F1 score at threshold 0.26 is 0.6591841970241149\n",
      "F1 score at threshold 0.27 is 0.6601991980338896\n",
      "F1 score at threshold 0.28 is 0.6608797807074794\n",
      "F1 score at threshold 0.29 is 0.6622760800842993\n",
      "F1 score at threshold 0.3 is 0.6634794156706508\n",
      "F1 score at threshold 0.31 is 0.6630937227842165\n",
      "F1 score at threshold 0.32 is 0.6642325895875592\n",
      "F1 score at threshold 0.33 is 0.6652594307503744\n",
      "F1 score at threshold 0.34 is 0.6655697243932539\n",
      "F1 score at threshold 0.35 is 0.6674502212389379\n",
      "F1 score at threshold 0.36 is 0.6685714285714286\n",
      "F1 score at threshold 0.37 is 0.6690546425059699\n",
      "F1 score at threshold 0.38 is 0.6698273422020944\n",
      "F1 score at threshold 0.39 is 0.6689492831157714\n",
      "F1 score at threshold 0.4 is 0.6680548574710994\n",
      "F1 score at threshold 0.41 is 0.668838690993339\n",
      "F1 score at threshold 0.42 is 0.6692913385826771\n",
      "F1 score at threshold 0.43 is 0.6682822941910848\n",
      "F1 score at threshold 0.44 is 0.6682436428149024\n",
      "F1 score at threshold 0.45 is 0.6680083482409064\n",
      "F1 score at threshold 0.46 is 0.6680700699195549\n",
      "F1 score at threshold 0.47 is 0.6664646158508865\n",
      "F1 score at threshold 0.48 is 0.6645796747346722\n",
      "F1 score at threshold 0.49 is 0.6637937668333974\n",
      "F1 score at threshold 0.5 is 0.6625757340375952\n"
     ]
    }
   ],
   "source": [
    "#look for a better threshold\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 2s 33us/step\n"
     ]
    }
   ],
   "source": [
    "pred_glove_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.9275418e-04],\n",
       "       [1.9369295e-04],\n",
       "       [1.9134153e-05],\n",
       "       ...,\n",
       "       [3.1709255e-04],\n",
       "       [2.6350641e-03],\n",
       "       [8.4229267e-01]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_glove_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#do a clean up\n",
    "del word_index, embeddings_index, all_embs, embedding_matrix, model\n",
    "import gc; gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wiki News FastText Embeddings:**\n",
    "\n",
    "Now let us use the FastText embeddings trained on Wiki News corpus in place of Glove embeddings and rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'D:\\\\ml_code\\\\embeddings\\\\wiki-news-300d-1M\\\\wiki-news-300d-1M.vec'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE,errors='ignore') if len(o)>100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999856, 300)\n"
     ]
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "print(all_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165640\n",
      "(50000, 300)\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "#len(word_index.items())\n",
    "#print(len(embedding_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 952162 samples, validate on 105796 samples\n",
      "Epoch 1/2\n",
      " - 121s - loss: 0.1154 - acc: 0.9556 - val_loss: 0.1054 - val_acc: 0.9585\n",
      "Epoch 2/2\n",
      " - 120s - loss: 0.0928 - acc: 0.9629 - val_loss: 0.1071 - val_acc: 0.9591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a6b9e33048>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105796/105796 [==============================] - ETA: 17 - ETA: 8 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 4s 35us/step\n"
     ]
    }
   ],
   "source": [
    "pred_fasttext_val_y = model.predict([val_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.606289037260392\n",
      "F1 score at threshold 0.11 is 0.6121956569423119\n",
      "F1 score at threshold 0.12 is 0.6185348434971824\n",
      "F1 score at threshold 0.13 is 0.6239918209701237\n",
      "F1 score at threshold 0.14 is 0.6302065305180571\n",
      "F1 score at threshold 0.15 is 0.6353684949950242\n",
      "F1 score at threshold 0.16 is 0.6399002197541129\n",
      "F1 score at threshold 0.17 is 0.6427282569469506\n",
      "F1 score at threshold 0.18 is 0.6464855646241929\n",
      "F1 score at threshold 0.19 is 0.6484788767089544\n",
      "F1 score at threshold 0.2 is 0.6519461077844312\n",
      "F1 score at threshold 0.21 is 0.6541879372282094\n",
      "F1 score at threshold 0.22 is 0.6566345724670026\n",
      "F1 score at threshold 0.23 is 0.6594072164948453\n",
      "F1 score at threshold 0.24 is 0.6612388458281769\n",
      "F1 score at threshold 0.25 is 0.6632894736842105\n",
      "F1 score at threshold 0.26 is 0.6652505808164619\n",
      "F1 score at threshold 0.27 is 0.6673369528788793\n",
      "F1 score at threshold 0.28 is 0.6679740329997296\n",
      "F1 score at threshold 0.29 is 0.6708099986340663\n",
      "F1 score at threshold 0.3 is 0.6718082908690263\n",
      "F1 score at threshold 0.31 is 0.6718500520652552\n",
      "F1 score at threshold 0.32 is 0.6717076244486453\n",
      "F1 score at threshold 0.33 is 0.6725513734905727\n",
      "F1 score at threshold 0.34 is 0.6721790576662628\n",
      "F1 score at threshold 0.35 is 0.6721759126185686\n",
      "F1 score at threshold 0.36 is 0.6716407098877218\n",
      "F1 score at threshold 0.37 is 0.6711389820621263\n",
      "F1 score at threshold 0.38 is 0.6691154863355864\n",
      "F1 score at threshold 0.39 is 0.6670127558587955\n",
      "F1 score at threshold 0.4 is 0.6664175199940205\n",
      "F1 score at threshold 0.41 is 0.6656134807793576\n",
      "F1 score at threshold 0.42 is 0.6643441381399575\n",
      "F1 score at threshold 0.43 is 0.662700228832952\n",
      "F1 score at threshold 0.44 is 0.662210954905124\n",
      "F1 score at threshold 0.45 is 0.6605703657780533\n",
      "F1 score at threshold 0.46 is 0.6594797281462386\n",
      "F1 score at threshold 0.47 is 0.6578491576129744\n",
      "F1 score at threshold 0.48 is 0.6570568667828292\n",
      "F1 score at threshold 0.49 is 0.6545309381237525\n",
      "F1 score at threshold 0.5 is 0.6522612258012692\n"
     ]
    }
   ],
   "source": [
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_fasttext_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 2s 34us/step\n"
     ]
    }
   ],
   "source": [
    "pred_fasttext_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "import gc; gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paragram Embeddings:**\n",
    "\n",
    "In this section, we can use the paragram embeddings and build the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'D:\\\\ml_code\\\\embeddings\\\\paragram_300_sl999\\\\paragram_300_sl999.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 15,144,705\n",
      "Trainable params: 15,144,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "300\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(max_features)\n",
    "print(embed_size)\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 952162 samples, validate on 105796 samples\n",
      "Epoch 1/2\n",
      " - 122s - loss: 0.1157 - acc: 0.9549 - val_loss: 0.1048 - val_acc: 0.9591\n",
      "Epoch 2/2\n",
      " - 122s - loss: 0.0955 - acc: 0.9618 - val_loss: 0.1054 - val_acc: 0.9593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a6e2e54208>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105796/105796 [==============================] - ETA: 25 - ETA: 10 - ETA: 7 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 4s 35us/step\n"
     ]
    }
   ],
   "source": [
    "pred_paragram_val_y = model.predict([val_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.6375881240327851\n",
      "F1 score at threshold 0.11 is 0.6424065420560747\n",
      "F1 score at threshold 0.12 is 0.6477333491771138\n",
      "F1 score at threshold 0.13 is 0.6519738435456527\n",
      "F1 score at threshold 0.14 is 0.6544316228823963\n",
      "F1 score at threshold 0.15 is 0.6583130727510753\n",
      "F1 score at threshold 0.16 is 0.6626627892274624\n",
      "F1 score at threshold 0.17 is 0.6657252888318357\n",
      "F1 score at threshold 0.18 is 0.6666233597505522\n",
      "F1 score at threshold 0.19 is 0.6682888333552546\n",
      "F1 score at threshold 0.2 is 0.6703026272031926\n",
      "F1 score at threshold 0.21 is 0.6706135629709364\n",
      "F1 score at threshold 0.22 is 0.6728298552103869\n",
      "F1 score at threshold 0.23 is 0.6736235067966497\n",
      "F1 score at threshold 0.24 is 0.6750346740638002\n",
      "F1 score at threshold 0.25 is 0.6752136752136753\n",
      "F1 score at threshold 0.26 is 0.676314860571832\n",
      "F1 score at threshold 0.27 is 0.6770833333333334\n",
      "F1 score at threshold 0.28 is 0.6774634708126395\n",
      "F1 score at threshold 0.29 is 0.6774123284687432\n",
      "F1 score at threshold 0.3 is 0.6760852060610497\n",
      "F1 score at threshold 0.31 is 0.6743894340736367\n",
      "F1 score at threshold 0.32 is 0.6741071428571428\n",
      "F1 score at threshold 0.33 is 0.6735230087831244\n",
      "F1 score at threshold 0.34 is 0.6714134222087563\n",
      "F1 score at threshold 0.35 is 0.669975565058033\n",
      "F1 score at threshold 0.36 is 0.6680006156687702\n",
      "F1 score at threshold 0.37 is 0.6663052737551305\n",
      "F1 score at threshold 0.38 is 0.6624472573839663\n",
      "F1 score at threshold 0.39 is 0.6593735243192193\n",
      "F1 score at threshold 0.4 is 0.659119696010133\n",
      "F1 score at threshold 0.41 is 0.656349712827058\n",
      "F1 score at threshold 0.42 is 0.6534717193659989\n",
      "F1 score at threshold 0.43 is 0.6504130892596792\n",
      "F1 score at threshold 0.44 is 0.647178900955336\n",
      "F1 score at threshold 0.45 is 0.6451983898792409\n",
      "F1 score at threshold 0.46 is 0.643436517132925\n",
      "F1 score at threshold 0.47 is 0.6404934566975078\n",
      "F1 score at threshold 0.48 is 0.6375252185608609\n",
      "F1 score at threshold 0.49 is 0.6356930902924969\n",
      "F1 score at threshold 0.5 is 0.6323881106935428\n"
     ]
    }
   ],
   "source": [
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_paragram_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 2s 33us/step\n"
     ]
    }
   ],
   "source": [
    "pred_paragram_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "#import gc; gc.collect()\n",
    "#time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_y = 0.33*pred_glove_val_y + 0.33*pred_fasttext_val_y + 0.33*pred_paragram_val_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5997540731632339\n",
      "F1 score at threshold 0.11 is 0.6082183186951067\n",
      "F1 score at threshold 0.12 is 0.6158604874406698\n",
      "F1 score at threshold 0.13 is 0.6229971212861876\n",
      "F1 score at threshold 0.14 is 0.6282242474454571\n",
      "F1 score at threshold 0.15 is 0.6337822671156004\n",
      "F1 score at threshold 0.16 is 0.640269298796143\n",
      "F1 score at threshold 0.17 is 0.6449855072463769\n",
      "F1 score at threshold 0.18 is 0.6496762801648028\n",
      "F1 score at threshold 0.19 is 0.6533627211532733\n",
      "F1 score at threshold 0.2 is 0.6573460286850669\n",
      "F1 score at threshold 0.21 is 0.6607317073170732\n",
      "F1 score at threshold 0.22 is 0.6644051070128908\n",
      "F1 score at threshold 0.23 is 0.6677059300367899\n",
      "F1 score at threshold 0.24 is 0.6705333501450007\n",
      "F1 score at threshold 0.25 is 0.6733443919867297\n",
      "F1 score at threshold 0.26 is 0.674739147236893\n",
      "F1 score at threshold 0.27 is 0.6765412849996751\n",
      "F1 score at threshold 0.28 is 0.6761579845164677\n",
      "F1 score at threshold 0.29 is 0.6773167174864113\n",
      "F1 score at threshold 0.3 is 0.6785379568884723\n",
      "F1 score at threshold 0.31 is 0.6798595164122654\n",
      "F1 score at threshold 0.32 is 0.6788490385926633\n",
      "F1 score at threshold 0.33 is 0.6804790748898677\n",
      "F1 score at threshold 0.34 is 0.6809901265470727\n",
      "F1 score at threshold 0.35 is 0.6817894515064259\n",
      "F1 score at threshold 0.36 is 0.6818020574671869\n",
      "F1 score at threshold 0.37 is 0.6825214899713468\n",
      "F1 score at threshold 0.38 is 0.6828352822289592\n",
      "F1 score at threshold 0.39 is 0.682079243911305\n",
      "F1 score at threshold 0.4 is 0.6806605504587157\n",
      "F1 score at threshold 0.41 is 0.6796805678793256\n",
      "F1 score at threshold 0.42 is 0.6787472035794184\n",
      "F1 score at threshold 0.43 is 0.6776498909200331\n",
      "F1 score at threshold 0.44 is 0.6771844660194175\n",
      "F1 score at threshold 0.45 is 0.6756922135536179\n",
      "F1 score at threshold 0.46 is 0.6742874797250328\n",
      "F1 score at threshold 0.47 is 0.6722754537664564\n",
      "F1 score at threshold 0.48 is 0.669754297825575\n",
      "F1 score at threshold 0.49 is 0.6686732673267326\n",
      "F1 score at threshold 0.5 is 0.6661870503597123\n"
     ]
    }
   ],
   "source": [
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = 0.33*pred_glove_test_y + 0.33*pred_fasttext_test_y + 0.33*pred_paragram_test_y\n",
    "pred_test_y = (pred_test_y>0.37).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "out_df['prediction'] = pred_test_y\n",
    "out_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
